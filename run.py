import litellm

if __name__ == '__main__':
    litellm.run_server()

    # --config ~/beyond/code/src/beyondwork.ai/modelproxy/default_config.yaml